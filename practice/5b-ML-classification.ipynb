{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab17d81",
   "metadata": {},
   "source": [
    "# Data management\n",
    "\n",
    "## Machine Learning - Classifications\n",
    "\n",
    "## [Malka Guillot](https://malkaguillot.github.io/)\n",
    "\n",
    "## HEC Liège | [ECON2306]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d29502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import patsy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a1143",
   "metadata": {},
   "source": [
    "## Part 1: toy example using a logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29173c0b",
   "metadata": {},
   "source": [
    "### Load & visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/beers.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d13b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.countplot(x='is_yummy', data=df)\n",
    "_ = plt.title('# Yummy vs not yummy')\n",
    "_ = plt.xlabel('Class (1==Yummy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4cc486",
   "metadata": {},
   "source": [
    "#### Prepare data: split features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfb8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns up to the last one:\n",
    "X = df.iloc[:, :-1]\n",
    "# only the last column:\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df327567",
   "metadata": {},
   "source": [
    "### Splitting into Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b02223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4368df",
   "metadata": {},
   "source": [
    "### Model Building and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399e25b",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae6d0d",
   "metadata": {},
   "source": [
    "Before we build the model, \n",
    "1. we use the standard scaler function to scale the values into a common range. \n",
    "2. Next, we create an instance of LogisticRegression() function for logistic regression.\n",
    "\n",
    "We are not passing any parameters to `LogisticRegression()` so it will assume default parameters. Some of the important parameters you should know are –\n",
    "\n",
    "- **penalty**:  It specifies the norm for the penalty\n",
    "  - Default = L2 \n",
    "\n",
    "- **C**:  It is the inverse of regularization strength\n",
    "  - Default = 1.0 \n",
    "\n",
    "- **solver**: It denotes the optimizer algorithm\n",
    "  - Default = ‘lbfgs’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e21d4",
   "metadata": {},
   "source": [
    "We are making use of `Pipeline` to create the model to streamline standard scalar and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18092326",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, solver='lbfgs') #syntax if you wand to add hyperparameters\n",
    "\n",
    "model1 = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de691a",
   "metadata": {},
   "source": [
    "#### Fit our model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccdb3f",
   "metadata": {},
   "source": [
    "#### Predictions for the class and for the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = model1.predict(X_train) # predicting on the training set\n",
    "y_train_hat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c98976",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat_probs = model1.predict_proba(X_train)[:,1] # probabilities of being in class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb23d07",
   "metadata": {},
   "source": [
    "We can see that the model predicts $y_i=1$ when $p_i>0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= pd.DataFrame({'y_train_hat': y_train_hat, 'y_train_hat_probs': y_train_hat_probs})\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['y_train_hat_probs'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc95b67",
   "metadata": {},
   "source": [
    "#### Performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62720f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, y_train_hat)*100\n",
    "train_auc_roc = roc_auc_score(y_train, y_train_hat_probs)*100\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat))\n",
    "print('Training AUC: %.4f %%' % train_auc_roc)\n",
    "print('Training accuracy: %.4f %%' % train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66e6d6",
   "metadata": {},
   "source": [
    "### Test set\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h4> Your turn</h4>\n",
    "Following the computation on the train set, compute for the test set:\n",
    "     \n",
    "    - the class & proba predictions\n",
    "    - the accuracy and AUC\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_test_hat = \n",
    "y_test_hat_probs = \n",
    "# Probabilities of being in class 1\n",
    "\n",
    "# Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e8192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_hat, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c94872",
   "metadata": {},
   "source": [
    "### Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a69e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_hat_probs)\n",
    "print(\"tresholds:\",  len(threshold))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04282f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a662c",
   "metadata": {},
   "source": [
    "We can further try to improve this model performance by hyperparameter tuning by changing the value of C or choosing other solvers available in `LogisticRegression()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689bcbd",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c279204",
   "metadata": {},
   "source": [
    "The objective is to build a classifier for whether a firm is going to default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c61a2",
   "metadata": {},
   "source": [
    "### Load & visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13869c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/bisnode_firms_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3cf073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install summarytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3aedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarytools import dfSummary\n",
    "dfSummary(data, is_collapsible = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.histplot(data=data, x=\"default_f\", stat=\"percent\") \n",
    "plt.title('Default frequency')\n",
    "plt.xlabel('Default frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0091f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['default']\n",
    "X=data.drop(columns='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5185ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323d6dc",
   "metadata": {},
   "source": [
    "All sets are balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ddc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Total ---\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"--- Train ---\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"--- Test ---\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58ac3c",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "There are so many variables !\n",
    "\n",
    "We are going to compare several models : \n",
    "- Logit with a selection of variables **M1**\n",
    "- Logit with a selection of variables **M2**\n",
    "- Regularized logit on **M2** variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e37535",
   "metadata": {},
   "source": [
    "Firm related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d074373",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm = [\"age\", \"age2\", \"new\", \"ind2_cat\", \"m_region_loc\", \"urban_m\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda65f4d",
   "metadata": {},
   "source": [
    "Human capital related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = [\n",
    "    \"female\",\n",
    "    \"ceo_age\",\n",
    "    \"flag_high_ceo_age\",\n",
    "    \"flag_low_ceo_age\",\n",
    "    \"flag_miss_ceo_age\",\n",
    "    \"ceo_count\",\n",
    "    \"labor_avg_mod\",\n",
    "    \"flag_miss_labor_avg\",\n",
    "    \"foreign_management\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa494e",
   "metadata": {},
   "source": [
    "Financial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a37d6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualityvars = [\"balsheet_flag\", \"balsheet_length\", \"balsheet_notfullyear\"]\n",
    "\n",
    "engvar = [\n",
    "    \"total_assets_bs\",\n",
    "    \"fixed_assets_bs\",\n",
    "    \"liq_assets_bs\",\n",
    "    \"curr_assets_bs\",\n",
    "    \"share_eq_bs\",\n",
    "    \"subscribed_cap_bs\",\n",
    "    \"intang_assets_bs\",\n",
    "    \"extra_exp_pl\",\n",
    "    \"extra_inc_pl\",\n",
    "    \"extra_profit_loss_pl\",\n",
    "    \"inc_bef_tax_pl\",\n",
    "    \"inventories_pl\",\n",
    "    \"material_exp_pl\",\n",
    "    \"profit_loss_year_pl\",\n",
    "    \"personnel_exp_pl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1635626",
   "metadata": {},
   "source": [
    "Growth variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35a902be",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [ \n",
    "    \"d1_sales_mil_log_mod\",\n",
    "    \"d1_sales_mil_log_mod_sq\",\n",
    "    \"flag_low_d1_sales_mil_log\",\n",
    "    \"flag_high_d1_sales_mil_log\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b967ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = [\n",
    "    \"sales_mil_log\",\n",
    "    \"sales_mil_log_sq\",\n",
    "    \"d1_sales_mil_log_mod\",\n",
    "    \"profit_loss_year_pl\",\n",
    "    \"fixed_assets_bs\",\n",
    "    \"share_eq_bs\",\n",
    "    \"age\",\n",
    "    \"foreign_management\",\n",
    "    \"ind2_cat\",\n",
    "]\n",
    "M2 = [\"sales_mil_log\", \"sales_mil_log_sq\"] + firm + engvar + d1 + hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefada7",
   "metadata": {},
   "source": [
    "#### Selection of the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d65141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1\n",
    "X_train_M1=X_train[M1]\n",
    "X_test_M1 =X_test[M1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a302a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2\n",
    "X_train_M2=X_train[M2]\n",
    "X_test_M2 =X_test[M2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1bbc8",
   "metadata": {},
   "source": [
    "#### Set up the method for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5398f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbebc6",
   "metadata": {},
   "source": [
    "#### No regularisation needed so setting the paremeter to very high value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "534d4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_value_logit = [1e20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecc5c8",
   "metadata": {},
   "source": [
    "#### Where we put the results of the different models, for comparison purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bbe01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy={}\n",
    "test_auc_roc={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a52f7",
   "metadata": {},
   "source": [
    "### Model 1: Logit\n",
    "#### Set up Logit model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e8ab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegressionCV(\n",
    "    Cs=C_value_logit,   #  # Cs: inverse of regularization strength.\n",
    "    cv=k,               # 5-fold cross-validation\n",
    "    refit=True,         # Refit the best estimator with the entire dataset\n",
    "    solver=\"newton-cg\", # Optimization algorithm\n",
    "    tol=1e-7,           # Tolerance for stopping criteria\n",
    "    random_state=42,    # Random seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2fe54",
   "metadata": {},
   "source": [
    "#### Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logit = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('log_reg', logistic)\n",
    "                          ])\n",
    "pipeline_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97fbf4",
   "metadata": {},
   "source": [
    "#### On M1 features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logit.fit(X_train_M1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbe260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_test_hat = pipeline_logit.predict(X_test_M1)\n",
    "y_test_hat_probs = pipeline_logit.predict_proba(X_test_M1)[:,1]\n",
    "\n",
    "# Metrics\n",
    "test_accuracy['logit_m1'] = accuracy_score(y_test, y_test_hat)*100\n",
    "test_auc_roc['logit_m1'] = roc_auc_score(y_test, y_test_hat_probs)*100\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "print('Testing AUC: %.4f %%' % test_auc_roc['logit_m1'])\n",
    "print('Testing accuracy: %.4f %%' % test_accuracy['logit_m1']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef439e",
   "metadata": {},
   "source": [
    "#### On M2 features set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d1ecb",
   "metadata": {},
   "source": [
    "We need to deal with all the features: depending on their type, the pre-processing will be different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e1130",
   "metadata": {},
   "source": [
    "##### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbaa070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector \n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)  # Selects all columns of type object\n",
    "categorical_features = categorical_columns_selector(X_train_M2) # Apply the selector to the training set\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ed525",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23557398",
   "metadata": {},
   "source": [
    "##### Numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [col for col in X_train_M2.columns if col not in categorical_features] # Select the columns that are not categorical\n",
    "len(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "numeric_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07340627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859449f",
   "metadata": {},
   "source": [
    "##### The pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append classifier to preprocessing pipeline. Now we have a full prediction pipeline.\n",
    "pipeline_logit = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", logistic)]\n",
    ")\n",
    "pipeline_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d91c4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4> Your turn: Fit the pipeline </h4>\n",
    "Following M1 example, estimate and evaluate a logit model with cross-validation using the M2 set of features.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58309ea4",
   "metadata": {},
   "source": [
    "##### Performances for M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd06be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8385143",
   "metadata": {},
   "source": [
    "#### Comparing performance for the 2 logit models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d76505",
   "metadata": {},
   "source": [
    "### Model 2: Lasso with standardized X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(10 ** np.arange(-1, -4.01, -1 / 3)) # 10^-1, 10^-0.67, 10^-0.33, 10^0, 10^0.33, 10^0.67, 10^1\n",
    "n_obs = X_train_M2.shape[0] * 4 / 5 # 4/5 of the training set\n",
    "C_values = [\n",
    "    1 / (l * n_obs) for l in lambdas\n",
    "]  # Cs are the inverse of regularization strength\n",
    "len(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94298290",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_lasso = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\", # L1 regularization = lasso \n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"roc_auc\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bc3d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4> Your turn: Create and implement the pipeline with the logistic lasso </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c87048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append classifier to preprocessing pipeline. Now we have a full prediction pipeline.\n",
    "pipeline_logistic_lasso = Pipeline(\n",
    " \n",
    " \n",
    "pipeline_logistic_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6657c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f59e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ded6d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline_logistic_lasso, X_train_M2, y_train, cv = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0079601",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = pipeline_logistic_lasso.predict(X_test_M2)\n",
    "y_test_hat_probs = pipeline_logistic_lasso.predict_proba(X_test_M2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8088bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy['logistic_lasso'] = accuracy_score(y_test, y_test_hat)*100\n",
    "test_auc_roc['logistic_lasso'] = roc_auc_score(y_test, y_test_hat_probs)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_hat_probs)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dd4e2",
   "metadata": {},
   "source": [
    "### Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbeda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f24f4",
   "metadata": {},
   "source": [
    "#### Deciding on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa6724",
   "metadata": {},
   "source": [
    "`logit_m2` seems to perform marginaly better on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e1d51",
   "metadata": {},
   "source": [
    "### Re-estimating the model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append classifier to preprocessing pipeline. Now we have a full prediction pipeline.\n",
    "pipeline_logit = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", logistic)]\n",
    ")\n",
    "pipeline_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39b68106",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_M2 = X[M2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84767e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logLasso=pipeline_logit.fit(X_M2, y)\n",
    "logLasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26b274",
   "metadata": {},
   "source": [
    "### Using the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "497e0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_new_hat = logLasso.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0f28e",
   "metadata": {},
   "source": [
    "## Going further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "251bbd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1e883",
   "metadata": {},
   "source": [
    "Let's look at one of the most powerful machine learning model: `xgboost` (cf. [documentation](https://xgboost.readthedocs.io/en/latest/index.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e6b8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "778fe63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"reg:squarederror\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append classifier to preprocessing pipeline. Now we have a full prediction pipeline.\n",
    "pipeline_xgp = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", xgb_model)]\n",
    ")\n",
    "pipeline_xgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=pipeline_xgp.fit(X_train_M2, y_train)\n",
    "model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5167c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = model_xgb.predict(X_test_M2)\n",
    "y_test_hat_probs = model_xgb.predict_proba(X_test_M2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f4b581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy['xgb'] = accuracy_score(y_test, y_test_hat)*100\n",
    "test_auc_roc['xgb'] = roc_auc_score(y_test, y_test_hat_probs)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32db3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataManagement2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
